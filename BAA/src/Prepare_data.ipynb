{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data from live bike_ped.data table\n",
    "## Database diagram\n",
    "\n",
    "![Figure 1. Data preparation](/opt/app/src/baa1003/data_preparation1.png)\n",
    "\n",
    "## Aggregate 15min and hourly live data into hourly data\n",
    "- Query to aggregate 15 min data into hourly data\n",
    "\n",
    "```sql\n",
    "insert into baa_temp.data (\n",
    "with fltz as (\n",
    "        select \n",
    "          flow_detector_id,\n",
    "          bike_ped.get_flow_detector_timezone(flow_detector_id) as timezone\n",
    "        from \n",
    "          bike_ped.flow_detectors\n",
    "  )\n",
    "  select \n",
    "    bpd.flow_detector_id,\n",
    "    bpd.upload_id,\n",
    "    date_trunc('hour', bpd.start_time) as start_time_utc,\n",
    "    date_trunc('hour', bpd.start_time at time zone fltz.timezone) \n",
    "      as start_time,\n",
    "    fltz.timezone as timezone,\n",
    "    date_trunc('hour', bpd.start_time at time zone fltz.timezone)\n",
    "      +'1 hour'::interval as end_time,\n",
    "    '1 hour'::INTERVAL as measure_period,\n",
    "    sum(volume) as volume\n",
    "from\n",
    "    bike_ped.data as bpd inner join fltz using(flow_detector_id)\n",
    "where \n",
    "    measure_period='00:15:00'\n",
    "    group by flow_detector_id, \n",
    "             upload_id, date_trunc('hour', start_time), \n",
    "             fltz.timezone , \n",
    "             date_trunc('hour', bpd.start_time at time zone fltz.timezone)\n",
    "    -- make sure we have 4 15-min records each hour\n",
    "    having count(start_time) = 4\n",
    ")\n",
    "```\n",
    "\n",
    "- Query to convert hourly data to houly data at hourly boundry \n",
    "  (some hourly data not recorded at hour boundry)\n",
    "\n",
    "```sql\n",
    "insert into baa_temp.data (\n",
    "  with fltz as (\n",
    "        select \n",
    "          flow_detector_id,\n",
    "          bike_ped.get_flow_detector_timezone(flow_detector_id) as timezone\n",
    "        from \n",
    "          bike_ped.flow_detectors\n",
    "  )\n",
    "  select \n",
    "    bpd.flow_detector_id,\n",
    "    bpd.upload_id,\n",
    "    date_trunc('hour', bpd.start_time) as start_time_utc,\n",
    "    date_trunc('hour', bpd.start_time at time zone fltz.timezone) \n",
    "      as start_time,\n",
    "    fltz.timezone as timezone,\n",
    "    date_trunc('hour', bpd.start_time at time zone fltz.timezone)\n",
    "      +'1 hour'::interval as end_time,\n",
    "    '1 hour'::INTERVAL as measure_period,\n",
    "    sum(volume) as volume\n",
    "from\n",
    "    bike_ped.data as bpd inner join fltz using(flow_detector_id)\n",
    "where \n",
    "    measure_period='01:00:00'\n",
    "    group by flow_detector_id, \n",
    "             upload_id, date_trunc('hour', start_time), \n",
    "             fltz.timezone , \n",
    "             date_trunc('hour', bpd.start_time at time zone fltz.timezone)\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>Result</h1><a href='./suspicious_data.csv?download=1' target='_blank'>suspicious_data.csv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utility import db_connect, query2csv\n",
    "from settings import  DBNAME, DBPASS, DBUSER, DBHOST\n",
    "\n",
    "qsql=\"\"\"\n",
    "select * from baa_temp.suspicious_data\n",
    "\"\"\"\n",
    "csvfile='suspicious_data.csv'\n",
    "query2csv(qsql,csvfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Remove suspicious data from data table\n",
    "- query\n",
    "\n",
    "```sql\n",
    "insert into baa_ex_sus.data (\n",
    "with susdata as (select \n",
    " bd.flow_detector_id,\n",
    " bd.start_time,\n",
    " bd.end_time,\n",
    " bs.start_date,\n",
    " bs.end_date,\n",
    " bd.measure_period,\n",
    " bd.volume,\n",
    " bs.suspect_data_id,\n",
    " bs.usable\n",
    "from\n",
    " baa_temp.data as bd, baa_temp.suspicious_data as bs\n",
    "where \n",
    " bd.flow_detector_id = bs.flow_detector_id\n",
    " and bs.usable=FALSE\n",
    " and bd.start_time between bs.start_date and bs.end_date +'23 hour'::interval\n",
    " )\n",
    "select \n",
    "  bd.flow_detector_id,\n",
    "  bd.upload_id,\n",
    "  bd.start_time_utc,\n",
    "  bd.start_time,\n",
    "  bd.timezone,\n",
    "  bd.end_time,\n",
    "  bd.measure_period,\n",
    "  bd.volume \n",
    "from \n",
    "  susdata as sd right join baa_temp.data as bd \n",
    "    using(flow_detector_id, start_time, end_time)\n",
    "where \n",
    "  sd.usable is NULL  \n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that total data rows = data_rows_excluding_suspicious_data + suspicious_data_rows\n",
    "- suspicious_data_rows **count**\n",
    "\n",
    "```sql\n",
    "with susdata as (select \n",
    " bd.flow_detector_id,\n",
    " bd.start_time,\n",
    " bd.end_time,\n",
    " bs.start_date,\n",
    " bs.end_date,\n",
    " bd.measure_period,\n",
    " bd.volume,\n",
    " bs.suspect_data_id,\n",
    " bs.usable\n",
    "from\n",
    " baa_temp.data as bd, baa_temp.suspicious_data as bs\n",
    "where \n",
    " bd.flow_detector_id = bs.flow_detector_id\n",
    " and bs.usable=FALSE\n",
    " and bd.start_time between bs.start_date and bs.end_date +'23 hour'::interval\n",
    " )\n",
    " select count(*) as sus_rows_count from susdata\n",
    " -- result --\n",
    " 473830\n",
    "```\n",
    " \n",
    "- data_rows_excluding_suspicious_data **count**\n",
    "\n",
    "```sql\n",
    " select count(*) as row_count_excluding_suspicious_data  from baa_ex_sus.data\n",
    " -- result --\n",
    " 12072542\n",
    "```\n",
    "- total data rows **count**\n",
    "\n",
    "```sql\n",
    "select count(*) as hourly_data_row_count  from baa_temp.data\n",
    " -- result --\n",
    " 12546372\n",
    "```\n",
    "- Verification:\n",
    "```\n",
    "12072542 + 473830 = 12546372\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating analysis_areas_hourly_volume and analysis_areas_daily_volume\n",
    "\n",
    "```sql\n",
    "CREATE TABLE baa_temp.analysis_areas_daily_volume_ex_sus\n",
    "(\n",
    "  analysis_area_id integer NOT NULL,\n",
    "  date timestamp with time zone NOT NULL,\n",
    "  volume integer NOT NULL\n",
    ");\n",
    "\n",
    "CREATE INDEX baa_temp_analysis_areas_daily_volume_date_ex_sus_idx\n",
    "  ON baa_temp.analysis_areas_daily_volume_ex_sus\n",
    "  USING btree\n",
    "  (date);\n",
    "  \n",
    "CREATE TABLE baa_temp.analysis_areas_hourly_volume_ex_sus\n",
    "(\n",
    "  analysis_area_id integer NOT NULL,\n",
    "  date timestamp with time zone NOT NULL,\n",
    "  hour character varying(10) NOT NULL,\n",
    "  volume integer NOT NULL\n",
    ");\n",
    "\n",
    "CREATE INDEX baa_temp_analysis_areas_hourly_volume_date_ex_sus_idx\n",
    "  ON baa_temp.analysis_areas_hourly_volume_ex_sus\n",
    "  USING btree\n",
    "  (date);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate analysis_areas_hourly_volume table with a join of analysis_areas and hourly aggregated data table\n",
    "\n",
    "```sql\n",
    "insert into baa_ex_sus.analysis_areas_hourly_volume (\n",
    "select\n",
    "  baaa.analysis_area_id,\n",
    "  date_trunc('day', bpd.start_time) as date,\n",
    "  to_char(bpd.start_time, 'HH24') as hour,\n",
    "  sum(bpd.volume) as volume\n",
    "from\n",
    "  baa.analysis_areas as baaa \n",
    "    inner join baa_ex_sus.data as bpd \n",
    "      on bpd.flow_detector_id = Any(baaa.flow_detector_list::int[])\n",
    "  group by analysis_area_id, bpd.start_time\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "### Populate analysis_areas_daily_volume table with aggregation of analysis_areas_hourly_volume into daily volume providing number of hourly records for a day is greater than 22 hours and less than 26 hours\n",
    "\n",
    "```sql\n",
    "insert into baa_ex_sus.analysis_areas_daily_volume (\n",
    "with predaily as (\n",
    "select\n",
    "  baaa.analysis_area_id,\n",
    "  date_trunc('day', bpd.start_time) as date,\n",
    "  count(to_char(bpd.start_time, 'HH24')) as hour,\n",
    "  -- count number of flow detectors in the group\n",
    "  array_length(baaa.flow_detector_list, 1) as fd_cnt,\n",
    "  sum(bpd.volume) as volume\n",
    "from\n",
    "  baa.analysis_areas as baaa \n",
    "    inner join baa_ex_sus.data as bpd \n",
    "      on bpd.flow_detector_id = Any(baaa.flow_detector_list::int[])\n",
    "  group by 1,2\n",
    ")\n",
    "select \n",
    "  analysis_area_id,\n",
    "  date,\n",
    "  volume\n",
    "from predaily\n",
    "where\n",
    "-- make sure flow detector daily hour count is >22 and < 26\n",
    "hour > fd_cnt*22\n",
    "and hour < fd_cnt*26 \n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
